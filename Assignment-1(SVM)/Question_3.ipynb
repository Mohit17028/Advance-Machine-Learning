{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImagesAndLabels(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dicte = cPickle.load(f)\n",
    "    images = dicte['data']\n",
    "    Matrix=[]\n",
    "    for i in images:\n",
    "        ingle_img_reshaped = np.transpose(np.reshape(i,(3, 32,32)), (1,2,0))\n",
    "        x=np.dot(ingle_img_reshaped[...,:3], [0.299, 0.587, 0.114])\n",
    "        x= x.flatten()\n",
    "        Matrix.append(x)\n",
    "    #images = np.transpose(images, (1,2,0))\n",
    "   \n",
    "    Matrix = np.array(Matrix)\n",
    "    labels = dicte['labels']\n",
    "    labels = np.array(labels)\n",
    "    print labels.shape\n",
    "    return Matrix, labels\n",
    " \n",
    "#     labels = dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "def extractCategories(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dict = cPickle.load(f)\n",
    "    return dict['label_names']\n",
    "\n",
    "def saveCifarImage(array, path, file):\n",
    "    # array is 3x32x32. cv2 needs 32x32x3\n",
    "    array = array.asnumpy().transpose(1,2,0)\n",
    "    # array is RGB. cv2 needs BGR\n",
    "    array = cv2.cvtColor(array, cv2.COLOR_RGB2BGR)\n",
    "    # save to PNG file\n",
    "    return cv2.imwrite(path+file+\".png\", array)\n",
    "\n",
    "path = \"/home/mohit/Desktop/Nptel/Week1_Deep Learning For Visual Learning/cifar10/cifar-10-batches-py/\"\n",
    "Train_data, Train_labels = extractImagesAndLabels(path, \"data_batch_1\")\n",
    "Train_data_2, Train_labels_2 = extractImagesAndLabels(path,\"data_batch_2\")\n",
    "Train_data_3, Train_labels_3 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_t = np.concatenate((Train_data, Train_data_2,Train_data_3), axis=0)\n",
    "Train_labels_t = np.concatenate((Train_labels, Train_labels_2, Train_labels_3), axis=0)\n",
    "\n",
    "Test_data, Test_labels = extractImagesAndLabels(path, \"test_batch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1024)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = extractCategories(path, \"batches.meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_f=[]\n",
    "Train_label_f=[]\n",
    "for i in range(Train_data_t.shape[0]):\n",
    "    if Train_labels_t[i]==3 or Train_labels_t[i]==5:\n",
    "        Train_data_f.append(Train_data_t[i])\n",
    "        Train_label_f.append(Train_labels_t[i])\n",
    "\n",
    "Train_data_f=np.array(Train_data_f)\n",
    "Train_label_f= np.array(Train_label_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## same for Test Data\n",
    "Test_data_f=[]\n",
    "Test_label_f=[]\n",
    "for i in range(Test_data.shape[0]):\n",
    "    if Test_labels[i]==3 or Test_labels[i]==5:\n",
    "        Test_data_f.append(Test_data[i])\n",
    "        Test_label_f.append(Test_labels[i])\n",
    "\n",
    "Test_data_f=np.array(Test_data_f)\n",
    "Test_label_f= np.array(Test_label_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5962, 1024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(100, 1024)\n",
      "(100,)\n",
      "(86, 1024)\n",
      "(86,)\n",
      "1\n",
      "(186, 1024)\n",
      "(186,)\n",
      "(143, 1024)\n",
      "(143,)\n",
      "2\n",
      "(243, 1024)\n",
      "(243,)\n",
      "(201, 1024)\n",
      "(201,)\n",
      "3\n",
      "(301, 1024)\n",
      "(301,)\n",
      "(248, 1024)\n",
      "(248,)\n",
      "4\n",
      "(348, 1024)\n",
      "(348,)\n",
      "(285, 1024)\n",
      "(285,)\n",
      "5\n",
      "(385, 1024)\n",
      "(385,)\n",
      "(330, 1024)\n",
      "(330,)\n",
      "6\n",
      "(430, 1024)\n",
      "(430,)\n",
      "(368, 1024)\n",
      "(368,)\n",
      "7\n",
      "(468, 1024)\n",
      "(468,)\n",
      "(386, 1024)\n",
      "(386,)\n",
      "8\n",
      "(486, 1024)\n",
      "(486,)\n",
      "(422, 1024)\n",
      "(422,)\n",
      "9\n",
      "(522, 1024)\n",
      "(522,)\n",
      "(461, 1024)\n",
      "(461,)\n",
      "10\n",
      "(561, 1024)\n",
      "(561,)\n",
      "(486, 1024)\n",
      "(486,)\n",
      "11\n",
      "(586, 1024)\n",
      "(586,)\n",
      "(511, 1024)\n",
      "(511,)\n",
      "12\n",
      "(611, 1024)\n",
      "(611,)\n",
      "(538, 1024)\n",
      "(538,)\n",
      "13\n",
      "(638, 1024)\n",
      "(638,)\n",
      "(551, 1024)\n",
      "(551,)\n",
      "14\n",
      "(651, 1024)\n",
      "(651,)\n",
      "(572, 1024)\n",
      "(572,)\n",
      "15\n",
      "(672, 1024)\n",
      "(672,)\n",
      "(600, 1024)\n",
      "(600,)\n",
      "16\n",
      "(700, 1024)\n",
      "(700,)\n",
      "(629, 1024)\n",
      "(629,)\n",
      "17\n",
      "(729, 1024)\n",
      "(729,)\n",
      "(650, 1024)\n",
      "(650,)\n",
      "18\n",
      "(750, 1024)\n",
      "(750,)\n",
      "(676, 1024)\n",
      "(676,)\n",
      "19\n",
      "(776, 1024)\n",
      "(776,)\n",
      "(695, 1024)\n",
      "(695,)\n",
      "20\n",
      "(795, 1024)\n",
      "(795,)\n",
      "(712, 1024)\n",
      "(712,)\n",
      "21\n",
      "(812, 1024)\n",
      "(812,)\n",
      "(732, 1024)\n",
      "(732,)\n",
      "22\n",
      "(832, 1024)\n",
      "(832,)\n",
      "(748, 1024)\n",
      "(748,)\n",
      "23\n",
      "(848, 1024)\n",
      "(848,)\n",
      "(763, 1024)\n",
      "(763,)\n",
      "24\n",
      "(863, 1024)\n",
      "(863,)\n",
      "(766, 1024)\n",
      "(766,)\n",
      "25\n",
      "(866, 1024)\n",
      "(866,)\n",
      "(789, 1024)\n",
      "(789,)\n",
      "26\n",
      "(889, 1024)\n",
      "(889,)\n",
      "(814, 1024)\n",
      "(814,)\n",
      "27\n",
      "(914, 1024)\n",
      "(914,)\n",
      "(823, 1024)\n",
      "(823,)\n",
      "28\n",
      "(923, 1024)\n",
      "(923,)\n",
      "(836, 1024)\n",
      "(836,)\n",
      "29\n",
      "(936, 1024)\n",
      "(936,)\n",
      "(857, 1024)\n",
      "(857,)\n",
      "30\n",
      "(957, 1024)\n",
      "(957,)\n",
      "(869, 1024)\n",
      "(869,)\n",
      "31\n",
      "(969, 1024)\n",
      "(969,)\n",
      "(876, 1024)\n",
      "(876,)\n",
      "32\n",
      "(976, 1024)\n",
      "(976,)\n",
      "(897, 1024)\n",
      "(897,)\n",
      "33\n",
      "(997, 1024)\n",
      "(997,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "Vec=[]\n",
    "Vec_labels=[]\n",
    "accu=[]\n",
    "Num_SV=[]\n",
    "iteration=[]\n",
    "Vec= np.array(Vec)\n",
    "Vec_labels=np.array(Vec_labels)\n",
    "for i in range(59):\n",
    "    print i\n",
    "    iteration.append(i+1)\n",
    "    Temp_data=Train_data_f[i*100:(i*100)+100]\n",
    "    Temp_label=Train_label_f[i*100:(i*100)+100]\n",
    "    if i>0:\n",
    "        Temp_data = np.concatenate((Temp_data,Vec),axis=0)\n",
    "        Temp_label = np.concatenate((Temp_label,Vec_label),axis=0)\n",
    "    clf = SVC(kernel=\"linear\")\n",
    "    print Temp_data.shape\n",
    "    print Temp_label.shape\n",
    "    clf.fit(Temp_data,Temp_label)\n",
    "    predict= clf.predict(Test_data_f)\n",
    "    acc = accuracy_score(predict, Test_label_f)\n",
    "    accu.append(acc)\n",
    "    vectors=clf.support_\n",
    "    Num_SV.append(len(vectors))\n",
    "    Vec_t=[]\n",
    "    Vec_labels_t=[]\n",
    "    for i in vectors:\n",
    "        Vec_t.append(Temp_data[i])\n",
    "        Vec_labels_t.append(Temp_label[i])\n",
    "    Vec_t=np.array(Vec_t)\n",
    "    Vec_labels_t=np.array(Vec_labels_t)\n",
    "    Vec=Vec_t\n",
    "    Vec_label=Vec_labels_t\n",
    "    print Vec.shape\n",
    "    print Vec_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
