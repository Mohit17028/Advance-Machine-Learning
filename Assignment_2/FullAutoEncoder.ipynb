{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_all_images(path_to_data):\n",
    "   \"\"\"\n",
    "   :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "   :return: an array containing all the images\n",
    "   \"\"\"\n",
    "\n",
    "   with open(path_to_data, 'rb') as f:\n",
    "       # read whole file in uint8 chunks\n",
    "       everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "       images = np.reshape(everything, (-1, 3, 96, 96))\n",
    "       \n",
    "\n",
    "       images = np.transpose(images, (0, 3, 2, 1))\n",
    "       images =  np.dot(images[:,:,:,0:3],[0.299,0.587,0.114])\n",
    "       print(images.shape)\n",
    "       images = np.reshape(images, (len(images), 96*96))\n",
    "       return images\n",
    "images = read_all_images(os.getcwd()+\"/data/stl10_binary/train_X.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(96*96, 96*48),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(96*48, 48*48),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(48*48,48*96),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(48*96,96*96))\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "model = autoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n",
      "/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:2747.7778\n",
      "epoch [2/100], loss:2127.6912\n",
      "epoch [3/100], loss:1783.0096\n",
      "epoch [4/100], loss:1611.5458\n",
      "epoch [5/100], loss:1435.5934\n",
      "epoch [6/100], loss:1350.7937\n",
      "epoch [7/100], loss:1288.6677\n",
      "epoch [8/100], loss:1228.7451\n",
      "epoch [9/100], loss:1188.5754\n",
      "epoch [10/100], loss:1131.3086\n",
      "epoch [11/100], loss:1094.1404\n",
      "epoch [12/100], loss:1062.4716\n",
      "epoch [13/100], loss:1034.8165\n",
      "epoch [14/100], loss:1004.9896\n",
      "epoch [15/100], loss:979.5984\n",
      "epoch [16/100], loss:954.9803\n",
      "epoch [17/100], loss:934.5781\n",
      "epoch [18/100], loss:911.6762\n",
      "epoch [19/100], loss:884.4239\n",
      "epoch [20/100], loss:863.7332\n",
      "epoch [21/100], loss:845.4066\n",
      "epoch [22/100], loss:830.5046\n",
      "epoch [23/100], loss:809.4958\n",
      "epoch [24/100], loss:792.9012\n",
      "epoch [25/100], loss:778.9006\n",
      "epoch [26/100], loss:765.5090\n",
      "epoch [27/100], loss:749.5656\n",
      "epoch [28/100], loss:736.0229\n",
      "epoch [29/100], loss:722.7300\n",
      "epoch [30/100], loss:709.7524\n",
      "epoch [31/100], loss:696.8722\n",
      "epoch [32/100], loss:688.4952\n",
      "epoch [33/100], loss:672.4913\n",
      "epoch [34/100], loss:662.7101\n",
      "epoch [35/100], loss:659.5182\n",
      "epoch [36/100], loss:641.6665\n",
      "epoch [37/100], loss:631.1013\n",
      "epoch [38/100], loss:620.9204\n",
      "epoch [39/100], loss:615.0012\n",
      "epoch [40/100], loss:601.3250\n",
      "epoch [41/100], loss:593.0954\n",
      "epoch [42/100], loss:590.8029\n",
      "epoch [43/100], loss:573.8911\n",
      "epoch [44/100], loss:565.8414\n",
      "epoch [45/100], loss:556.8315\n",
      "epoch [46/100], loss:549.4517\n",
      "epoch [47/100], loss:543.3115\n",
      "epoch [48/100], loss:534.6381\n",
      "epoch [49/100], loss:529.5892\n",
      "epoch [50/100], loss:521.0165\n",
      "epoch [51/100], loss:513.3065\n",
      "epoch [52/100], loss:508.6859\n",
      "epoch [53/100], loss:516.1998\n",
      "epoch [54/100], loss:501.2350\n",
      "epoch [55/100], loss:486.3550\n",
      "epoch [56/100], loss:481.2408\n",
      "epoch [57/100], loss:474.1212\n",
      "epoch [58/100], loss:474.0589\n",
      "epoch [59/100], loss:463.9448\n",
      "epoch [60/100], loss:458.0667\n",
      "epoch [61/100], loss:456.5701\n",
      "epoch [62/100], loss:448.1458\n",
      "epoch [63/100], loss:443.2665\n",
      "epoch [64/100], loss:437.0897\n",
      "epoch [65/100], loss:433.5719\n",
      "epoch [66/100], loss:429.0787\n",
      "epoch [67/100], loss:421.6526\n",
      "epoch [68/100], loss:418.8871\n",
      "epoch [69/100], loss:416.2343\n",
      "epoch [70/100], loss:408.7546\n",
      "epoch [71/100], loss:407.8633\n",
      "epoch [72/100], loss:400.6116\n",
      "epoch [73/100], loss:395.8737\n",
      "epoch [74/100], loss:391.7522\n",
      "epoch [75/100], loss:388.7032\n",
      "epoch [76/100], loss:385.4488\n",
      "epoch [77/100], loss:384.7462\n",
      "epoch [78/100], loss:375.9799\n",
      "epoch [79/100], loss:372.5439\n",
      "epoch [80/100], loss:369.2303\n",
      "epoch [81/100], loss:364.9441\n",
      "epoch [82/100], loss:362.6869\n",
      "epoch [83/100], loss:358.3921\n",
      "epoch [84/100], loss:356.3222\n",
      "epoch [85/100], loss:352.7350\n",
      "epoch [86/100], loss:348.2075\n",
      "epoch [87/100], loss:345.5178\n",
      "epoch [88/100], loss:344.5807\n",
      "epoch [89/100], loss:340.1206\n",
      "epoch [90/100], loss:336.3799\n",
      "epoch [91/100], loss:334.3922\n",
      "epoch [92/100], loss:330.1727\n",
      "epoch [93/100], loss:329.3383\n",
      "epoch [94/100], loss:324.6974\n",
      "epoch [95/100], loss:322.1850\n",
      "epoch [96/100], loss:321.2129\n",
      "epoch [97/100], loss:317.2235\n",
      "epoch [98/100], loss:316.2361\n",
      "epoch [99/100], loss:311.6783\n",
      "epoch [100/100], loss:307.6011\n"
     ]
    }
   ],
   "source": [
    "lo =[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0,5000, batch_size):\n",
    "        batch_x = images[i:i+500]\n",
    "        batch_x = Variable(torch.cuda.FloatTensor(batch_x)).cuda()\n",
    "        \n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output, batch_x)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    lo.append(loss.data[0])\n",
    "#torch.save(model, './full_new_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3f8b87898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ep = [i+1 for i in range(100)]\n",
    "plt.plot(lo,ep,linestyle='dashed')\n",
    "### plot ROC\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epoch')\n",
    "plt.title('epoch vs loss in full Autoencoder')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[40].reshape(96,96), interpolation='none')\n",
    "model1 = torch.load(\"./funn_autoencoder.pth\")\n",
    "images_reconstructed = model1.encoder(Variable(torch.FloatTensor(images)))\n",
    "images_reconstructed = model1.decoder(Variable(torch.FloatTensor(images_reconstructed)))\n",
    "#plt.imshow(images_reconstructed[1].data.numpy().reshape(96,96), interpolation='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf58381c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images_reconstructed[40].data.numpy().reshape(96,96), interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(model,\"./full_new_autoencoder.pth\")\n",
    "# model = torch.load(\"./full_new_autoencoder.pth\")\n",
    "feature_rep = model.encoder(Variable(torch.cuda.FloatTensor(images)))\n",
    "\n",
    "\n",
    "class nu_net(nn.Module):\n",
    "   def __init__(self,features):\n",
    "       super(nu_net,self).__init__()\n",
    "       self.features=features\n",
    "       self.arch=nn.Sequential(\n",
    "               nn.Linear(features,int(features/2)),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(int(features/2),int(features/4)),\n",
    "               nn.ReLU(),\n",
    "               nn.Linear(int(features/4),10),\n",
    "               nn.Softmax()\n",
    "       )\n",
    "   def forward(self,x):\n",
    "       x = self.arch(x)\n",
    "       return x\n",
    "\n",
    "nn_epoch=100\n",
    "classifier = nu_net(2304).cuda()\n",
    "optimizer_nn = torch.optim.SGD(classifier.parameters(), lr=0.01)\n",
    "criterion_nn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "# class NN(nn.Module):\n",
    "#   def __init__(self,input_size, hidden_size1,hidden_size2, num_classes):\n",
    "#         super(NN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "#         self.relu = nn.ReLU(True)\n",
    "#         self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "#         self.output = nn.Linear(hidden_size2, num_classes)\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#   def forward(self, x):\n",
    "        \n",
    "#         out = self.fc1(x)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.output(out)\n",
    "#         out = self.softmax(out)\n",
    "        \n",
    "#         return out\n",
    "  \n",
    "\n",
    "# NeuralNet = NN(48*48, 48*24,24*24,10).cuda()\n",
    "# criterion_net = nn.MSELoss()\n",
    "# learning_rate=0.001\n",
    "# optimizer_net = torch.optim.SGD(NeuralNet.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def read_all_labels(path_to_data):\n",
    "   \"\"\"\n",
    "   :param path_to_data: the file containing the binary images from the STL-10 dataset\n",
    "   :return: an array containing all the images\n",
    "   \"\"\"\n",
    "\n",
    "   with open(path_to_data, 'rb') as f:\n",
    "       # read whole file in uint8 chunks\n",
    "       everything = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "       return everything\n",
    "\n",
    "\n",
    "label = read_all_labels(os.getcwd()+\"/data/stl10_binary/train_y.bin\")\n",
    "epochs = 100\n",
    "label_oh = np.zeros((label.size,label.max()))\n",
    "label_oh[np.arange(5000),label-1]=1\n",
    "label=label-1\n",
    "label = Variable(torch.cuda.FloatTensor(label))\n",
    "label_oh = Variable(torch.cuda.FloatTensor(label_oh))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/envs/mohitpy36/lib/python3.6/site-packages/torch/nn/modules/container.py:91: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  loss:  8113.60986328125\n",
      "epoch:  1  loss:  8113.60986328125\n",
      "epoch:  2  loss:  8113.60986328125\n",
      "epoch:  3  loss:  8113.60986328125\n",
      "epoch:  4  loss:  8113.60986328125\n",
      "epoch:  5  loss:  8113.60986328125\n",
      "epoch:  6  loss:  8113.60986328125\n",
      "epoch:  7  loss:  8113.60986328125\n",
      "epoch:  8  loss:  8113.60986328125\n",
      "epoch:  9  loss:  8113.60986328125\n",
      "epoch:  10  loss:  8113.60986328125\n",
      "epoch:  11  loss:  8113.60986328125\n",
      "epoch:  12  loss:  8113.60986328125\n",
      "epoch:  13  loss:  8113.60986328125\n",
      "epoch:  14  loss:  8113.60986328125\n",
      "epoch:  15  loss:  8113.60986328125\n",
      "epoch:  16  loss:  8113.60986328125\n",
      "epoch:  17  loss:  8113.60986328125\n",
      "epoch:  18  loss:  8113.60986328125\n",
      "epoch:  19  loss:  8113.60986328125\n",
      "epoch:  20  loss:  8113.60986328125\n",
      "epoch:  21  loss:  8113.60986328125\n",
      "epoch:  22  loss:  8113.60986328125\n",
      "epoch:  23  loss:  8113.60986328125\n",
      "epoch:  24  loss:  8113.60986328125\n",
      "epoch:  25  loss:  8113.60986328125\n",
      "epoch:  26  loss:  8113.60986328125\n",
      "epoch:  27  loss:  8113.60986328125\n",
      "epoch:  28  loss:  8113.60986328125\n",
      "epoch:  29  loss:  8113.60986328125\n",
      "epoch:  30  loss:  8113.60986328125\n",
      "epoch:  31  loss:  8113.60986328125\n",
      "epoch:  32  loss:  8113.60986328125\n",
      "epoch:  33  loss:  8113.60986328125\n",
      "epoch:  34  loss:  8113.60986328125\n",
      "epoch:  35  loss:  8113.60986328125\n",
      "epoch:  36  loss:  8113.60986328125\n",
      "epoch:  37  loss:  8113.60986328125\n",
      "epoch:  38  loss:  8113.60986328125\n",
      "epoch:  39  loss:  8113.60986328125\n",
      "epoch:  40  loss:  8113.60986328125\n",
      "epoch:  41  loss:  8113.60986328125\n",
      "epoch:  42  loss:  8113.60986328125\n",
      "epoch:  43  loss:  8113.60986328125\n",
      "epoch:  44  loss:  8113.60986328125\n",
      "epoch:  45  loss:  8113.60986328125\n",
      "epoch:  46  loss:  8113.60986328125\n",
      "epoch:  47  loss:  8113.60986328125\n",
      "epoch:  48  loss:  8113.60986328125\n",
      "epoch:  49  loss:  8113.60986328125\n",
      "epoch:  50  loss:  8113.60986328125\n",
      "epoch:  51  loss:  8113.60986328125\n",
      "epoch:  52  loss:  8113.60986328125\n",
      "epoch:  53  loss:  8113.60986328125\n",
      "epoch:  54  loss:  8113.60986328125\n",
      "epoch:  55  loss:  8113.60986328125\n",
      "epoch:  56  loss:  8113.60986328125\n",
      "epoch:  57  loss:  8113.60986328125\n",
      "epoch:  58  loss:  8113.60986328125\n",
      "epoch:  59  loss:  8113.60986328125\n",
      "epoch:  60  loss:  8113.60986328125\n",
      "epoch:  61  loss:  8113.60986328125\n",
      "epoch:  62  loss:  8113.60986328125\n",
      "epoch:  63  loss:  8113.60986328125\n",
      "epoch:  64  loss:  8113.60986328125\n",
      "epoch:  65  loss:  8113.60986328125\n",
      "epoch:  66  loss:  8113.60986328125\n",
      "epoch:  67  loss:  8113.60986328125\n",
      "epoch:  68  loss:  8113.60986328125\n",
      "epoch:  69  loss:  8113.60986328125\n",
      "epoch:  70  loss:  8113.60986328125\n",
      "epoch:  71  loss:  8113.60986328125\n",
      "epoch:  72  loss:  8113.60986328125\n",
      "epoch:  73  loss:  8113.60986328125\n",
      "epoch:  74  loss:  8113.60986328125\n",
      "epoch:  75  loss:  8113.60986328125\n",
      "epoch:  76  loss:  8113.60986328125\n",
      "epoch:  77  loss:  8113.60986328125\n",
      "epoch:  78  loss:  8113.60986328125\n",
      "epoch:  79  loss:  8113.60986328125\n",
      "epoch:  80  loss:  8113.60986328125\n",
      "epoch:  81  loss:  8113.60986328125\n",
      "epoch:  82  loss:  8113.60986328125\n",
      "epoch:  83  loss:  8113.60986328125\n",
      "epoch:  84  loss:  8113.60986328125\n",
      "epoch:  85  loss:  8113.60986328125\n",
      "epoch:  86  loss:  8113.60986328125\n",
      "epoch:  87  loss:  8113.60986328125\n",
      "epoch:  88  loss:  8113.60986328125\n",
      "epoch:  89  loss:  8113.60986328125\n",
      "epoch:  90  loss:  8113.60986328125\n",
      "epoch:  91  loss:  8113.60986328125\n",
      "epoch:  92  loss:  8113.60986328125\n",
      "epoch:  93  loss:  8113.60986328125\n",
      "epoch:  94  loss:  8113.60986328125\n",
      "epoch:  95  loss:  8113.60986328125\n",
      "epoch:  96  loss:  8113.60986328125\n",
      "epoch:  97  loss:  8113.60986328125\n",
      "epoch:  98  loss:  8113.60986328125\n",
      "epoch:  99  loss:  8113.60986328125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nn_epoch):\n",
    "   pred_labels = classifier(feature_rep)\n",
    "   loss=criterion_nn(label_oh,pred_labels)\n",
    "   print('epoch: ', epoch,' loss: ', loss.item())\n",
    "   optimizer.zero_grad()\n",
    "   loss.backward(retain_graph=True)\n",
    "   optimizer.step()\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     batch_x =feature_rep\n",
    "#     output = NeuralNet(batch_x)\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     output = Variable(torch.cuda.FloatTensor(output),requires_grad=True)\n",
    "#     label_batch = label_oh\n",
    "#     label_batch = Variable(torch.cuda.FloatTensor(label_batch))\n",
    "#     loss_net = criterion_net(output,label_batch)\n",
    "# #     print(loss)\n",
    "#     optimizer_net.zero_grad()\n",
    "#     loss_net.backward()\n",
    "#     optimizer_net.step() \n",
    "#     print (loss, \"  in epoch  \", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 96, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/envs/mohitpy36/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "test_images = read_all_images(os.getcwd()+\"/data/stl10_binary/test_X.bin\")\n",
    "test_fea= model.encoder(Variable(torch.cuda.FloatTensor(test_images)))\n",
    "# test_fea=model_inner.encoder(test_fea)\n",
    "y_pred= NeuralNet(test_fea)\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "y_pred = y_pred+1\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real = read_all_labels(os.getcwd()+\"/data/stl10_binary/test_y.bin\")\n",
    "\n",
    "def Accuracy(pred, real):\n",
    "  aa=0\n",
    "  for i in range(len(real)):\n",
    "    if real[i]==y_pred[i]:\n",
    "        aa += 1\n",
    "    else:\n",
    "      continue\n",
    "  return aa\n",
    "\n",
    "aa=Accuracy(y_pred,real)\n",
    "acc = aa/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [1/100], loss:2863.6841\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/envs/mohitpy36/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [2/100], loss:2237.3809\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [3/100], loss:1817.1423\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [4/100], loss:1679.7734\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [5/100], loss:1495.9078\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [6/100], loss:1386.5559\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [7/100], loss:1325.2570\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [8/100], loss:1274.2959\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [9/100], loss:1225.6429\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [10/100], loss:1177.7272\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [11/100], loss:1136.0890\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [12/100], loss:1101.3586\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [13/100], loss:1072.2476\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [14/100], loss:1044.0718\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [15/100], loss:1017.6837\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [16/100], loss:992.8904\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [17/100], loss:966.2915\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [18/100], loss:943.1461\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [19/100], loss:922.5145\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [20/100], loss:897.9597\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [21/100], loss:878.2000\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [22/100], loss:860.4409\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [23/100], loss:845.6105\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [24/100], loss:824.3909\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [25/100], loss:808.9296\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [26/100], loss:794.4655\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [27/100], loss:782.0916\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [28/100], loss:769.2475\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [29/100], loss:753.2744\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [30/100], loss:739.4221\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [31/100], loss:724.6728\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [32/100], loss:711.8462\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [33/100], loss:698.7313\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [34/100], loss:688.4492\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [35/100], loss:674.2285\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [36/100], loss:663.0450\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [37/100], loss:655.2045\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [38/100], loss:649.8248\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [39/100], loss:630.3306\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [40/100], loss:625.7443\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [41/100], loss:612.2032\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [42/100], loss:601.6804\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [43/100], loss:593.4030\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [44/100], loss:585.6772\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [45/100], loss:605.9326\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [46/100], loss:576.0345\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [47/100], loss:558.0222\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [48/100], loss:552.1089\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [49/100], loss:544.2933\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [50/100], loss:536.8087\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [51/100], loss:530.9982\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [52/100], loss:525.1481\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [53/100], loss:517.4866\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [54/100], loss:511.6495\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [55/100], loss:506.0515\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [56/100], loss:501.5640\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [57/100], loss:495.4802\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [58/100], loss:491.7652\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [59/100], loss:488.5819\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [60/100], loss:480.8771\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [61/100], loss:472.6244\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [62/100], loss:469.8070\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [63/100], loss:464.9071\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [64/100], loss:458.4881\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [65/100], loss:453.1116\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [66/100], loss:447.9086\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [67/100], loss:446.1223\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [68/100], loss:442.1332\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [69/100], loss:440.0275\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [70/100], loss:431.2847\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [71/100], loss:428.8430\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [72/100], loss:423.8946\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [73/100], loss:418.5760\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [74/100], loss:414.0411\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [75/100], loss:409.6431\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [76/100], loss:406.9707\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [77/100], loss:406.8992\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [78/100], loss:398.4383\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [79/100], loss:394.0571\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [80/100], loss:393.2619\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [81/100], loss:387.0276\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [82/100], loss:385.5382\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [83/100], loss:381.9215\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [84/100], loss:377.4136\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [85/100], loss:375.4188\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [86/100], loss:373.1990\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [87/100], loss:368.3025\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [88/100], loss:367.1321\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [89/100], loss:363.6582\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [90/100], loss:359.5704\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [91/100], loss:356.5073\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [92/100], loss:356.4525\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [93/100], loss:351.0616\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [94/100], loss:348.7345\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [95/100], loss:344.8016\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "one layers parameters\n",
      "epoch [96/100], loss:343.4301\n"
     ]
    }
   ],
   "source": [
    "#3rd part\n",
    "\n",
    "\n",
    "def l2_penalty(model2):\n",
    "#    reg_lambda=1.0\n",
    "   l2_r=0\n",
    "   for weight in model2.parameters():\n",
    "        l2_r+= weight.norm(2)\n",
    "#    print(\"one layers parameters\")\n",
    "   return l2_r**0.5\n",
    "\n",
    "def l1_penalty(model2):\n",
    "    l1_r=0\n",
    "    for weight in model2.parameters():\n",
    "        l1_r += weight.norm(1)\n",
    "#     print(\"one layers parameters\")\n",
    "    return l1_r\n",
    "    \n",
    "def Model_Caller(norm):\n",
    "    model2 = autoencoder().cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    num_epochs = 50\n",
    "    batch_size = 100\n",
    "    learning_rate = 0.0001\n",
    "    optimizer = optim.Adam(model2.parameters(), lr = learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0,5000, batch_size):\n",
    "            batch_x = images[i:i+500]\n",
    "            batch_x = Variable(torch.cuda.FloatTensor(batch_x))\n",
    "            if norm ==1:\n",
    "                l1_loss = l1_penalty(model2)\n",
    "                norm_loss = l1_loss\n",
    "            elif norm == 2:\n",
    "                l2_loss = l2_penalty(model2)\n",
    "                norm_loss = l2_loss\n",
    "            else:\n",
    "                l1_loss = l1_penalty(model2)\n",
    "                l2_loss = l2_penalty(model2)\n",
    "                elastic = 0.5*l1_loss +0.5*l2_loss\n",
    "                norm_loss = elastic\n",
    "            output = model2(batch_x)\n",
    "    #         l2_loss = l2_penalty(model)\n",
    "\n",
    "    #         elastic = 0.5*l1_loss +0.5*l2_loss\n",
    "            loss = criterion(output, batch_x)\n",
    "            \n",
    "            loss+= norm_loss\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    feature_rep = model2.encoder(images)\n",
    "    return feature_rep\n",
    "     \n",
    "feature_rep = Model_Caller(2)\n",
    "def Neural_nework(feature_rep):\n",
    "    model_nn = NN(48*48,48*24,24*24,10).cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    learning_rate=0.001\n",
    "    optimizer = torch.optim.SGD(model_nn.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        batch_x =feature_rep\n",
    "        output = NeuralNet(batch_x)\n",
    "        output = output.data.numpy()\n",
    "        output = Variable(torch.cuda.FloatTensor(output),requires_grad=True)\n",
    "        label_batch = label_oh\n",
    "        label_batch = Variable(torch.cuda.FloatTensor(label_batch))\n",
    "        loss = criterion(output,label_batch)\n",
    "    #     print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        print (loss.data[0], \"  in epoch  \", epoch)\n",
    "        test_images = read_all_images(os.getcwd()+\"/data/stl10_binary/test_X.bin\")\n",
    "        test_fea= model.encoder(Variable(torch.FloatTensor(test_images)))\n",
    "        # test_fea=model_inner.encoder(test_fea)\n",
    "        y_pred= NeuralNet(test_fea)\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        y_pred = y_pred+1\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        aa=Accuracy(y_pred,real)\n",
    "        acc = aa/len(y_pred)\n",
    "        print (\"Accuracy :\",acc)\n",
    "        return acc\n",
    "acc = Neural_nework(feature_rep)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "##########################\n",
    "#L1-L2 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-17-edca2c5bcdc8>, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-edca2c5bcdc8>\"\u001b[0;36m, line \u001b[0;32m61\u001b[0m\n\u001b[0;31m    feature_rep = model2.encoder(images)\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#4th Part\n",
    "class autoencoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder2, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(96*96, 96*48),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(96*48, 48*48),\n",
    "            nn.ReLU(True))\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Linear(48*48,10),\n",
    "                nn.ReLU(True),\n",
    "                nn.Softmax(dim=1))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(48*48,48*96),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(48*96,96*96))\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "model = autoencoder2().cuda()\n",
    "criterion_1= nn.MSELoss()\n",
    "criterion_2 = nn.MSELoss\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "        for i in range(0,5000, batch_size):\n",
    "            batch_x = images[i:i+500]\n",
    "            batch_x = Variable(torch.cuda.FloatTensor(batch_x))\n",
    "            batch_y = label_oh[i:i+500]\n",
    "#             if norm ==1:\n",
    "#                 l1_loss = l1_penalty(model2)\n",
    "#                 norm_loss = l1_loss\n",
    "#             elif norm == 2:\n",
    "#                 l2_loss = l2_penalty(model2)\n",
    "#                 norm_loss = l2_loss\n",
    "#             else:\n",
    "#                 l1_loss = l1_penalty(model2)\n",
    "#                 l2_loss = l2_penalty(model2)\n",
    "#                 elastic = 0.5*l1_loss +0.5*l2_loss\n",
    "#                 norm_loss = elastic\n",
    "            output = model2(batch_x)\n",
    "    #         l2_loss = l2_penalty(model)\n",
    "\n",
    "    #         elastic = 0.5*l1_loss +0.5*l2_loss\n",
    "            loss_1 = criterion_1(output, batch_x)\n",
    "            loss_1 = criterion_2(output, )\n",
    "            loss+= norm_loss\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "    feature_rep = model2.encoder(images)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
