{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"./cifar/\"\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extractImagesAndLabels(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dicte = pickle.load(f,encoding='bytes')\n",
    "    images = dicte[b'data']\n",
    "    Matrix=[]\n",
    "    for i in images:\n",
    "        ingle_img_reshaped = np.transpose(np.reshape(i,(3, 32,32)), (1,2,0))\n",
    "        #x=np.dot(ingle_img_reshaped[...,:3], [0.299, 0.587, 0.114])\n",
    "        x= ingle_img_reshaped.flatten()\n",
    "        Matrix.append(x)\n",
    "    #images = np.transpose(images, (1,2,0))\n",
    "   \n",
    "    Matrix = np.array(Matrix)\n",
    "    labels = dicte[b'labels']\n",
    "    labels = np.array(labels)\n",
    "    #print labels.shape\n",
    "    return Matrix, labels\n",
    " \n",
    "#     labels = dict['labels']\n",
    "\n",
    "def extractCategories(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dict = pickle.load(f,encoding='bytes')\n",
    "    return dict[b'label_names']\n",
    "\n",
    "def saveCifarImage(array, path, file):\n",
    "    # array is 3x32x32. cv2 needs 32x32x3\n",
    "    array = array.asnumpy().transpose(1,2,0)\n",
    "    # array is RGB. cv2 needs BGR\n",
    "    array = cv2.cvtColor(array, cv2.COLOR_RGB2BGR)\n",
    "    # save to PNG file\n",
    "    return cv2.imwrite(path+file+\".png\", array)\n",
    "\n",
    "\n",
    "Train_data, Train_labels = extractImagesAndLabels(path, \"data_batch_1\")\n",
    "Train_data_2, Train_labels_2 = extractImagesAndLabels(path,\"data_batch_2\")\n",
    "Train_data_3, Train_labels_3 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_3, Train_labels_3 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_4, Train_labels_4 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_5, Train_labels_5 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_t = np.concatenate((Train_data, Train_data_2,Train_data_3,Train_data_4,Train_data_5), axis=0)\n",
    "Train_labels_t = np.concatenate((Train_labels,Train_labels_2,Train_labels_3,Train_labels_4,Train_labels_5), axis=0)\n",
    "Test_data, Test_labels = extractImagesAndLabels(path, \"test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# X = torch.FloatTensor(X.train.shape[0], X_train.shape[1])\n",
    "\n",
    "    \n",
    "# D = torch.FloatTensor(X_train.shape[1],k)\n",
    "\n",
    "# R = torch.FLoatTensor(k,X_train.shape[0])\n",
    "D_weights = torch.FloatTensor(10, 10).normal_()\n",
    "R_weights = torch.FloatTensor(10, 10).normal_()\n",
    "\n",
    "\n",
    "# image shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# def load():\n",
    "#     files = os.path.join(DATA_DIR,'stl10_binary')\n",
    "#     cross_val_indices = []\n",
    "#     with open(os.path.join(files, \"fold_indices.txt\"), \"r\") as ins:\n",
    "#         for line in ins:\n",
    "#             cross_val_indices.append([int(x) for x in line.rstrip().split(' ')])\n",
    "#     X_train = read_all_images(os.path.join(files,\"train_X.bin\")).astype('float32')\n",
    "#     Y_train = read_labels(os.path.join(files,\"train_y.bin\"))\n",
    "#     X_test = read_all_images(os.path.join(files,\"test_X.bin\")).astype('float32')\n",
    "#     Y_test = read_labels(os.path.join(files,\"test_y.bin\"))\n",
    "#     X_train /= 255.\n",
    "#     X_test /= 255.\n",
    "#     return (X_train, Y_train), (X_test, Y_test), cross_val_indices\n",
    "\n",
    "# def unlabelled_data():\n",
    "#     files = os.path.join(DATA_DIR,'stl10_binary')\n",
    "#     unlabelled_x = read_all_images(os.path.join(files,\"unlabeled_X.bin\")).astype('float32')\n",
    "#     unlabelled_x /= 255.\n",
    "#     return unlabelled_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-89f4af898a25>\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 69, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/home/mohit1_aml/anaconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can't optimize a non-leaf Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c9e5621f32a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#     return R_train.T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m# features_test = find_reprs(test_flat_X, D, 0.01, 100, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#features_test = np.linalg.pinv(test_flat_X, D.T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-c9e5621f32a4>\u001b[0m in \u001b[0;36mdictionary_learning\u001b[0;34m(X_train, lambda_val, k, learning_rate)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mD_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mR_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    191\u001b[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can't optimize a non-leaf Tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "\n",
    "# from load_data import load, unlabelled_data\n",
    "\n",
    "# Don't hog GPU\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.Session(config=config)\n",
    "import torch.optim as optim\n",
    "\n",
    "def dictionary_learning(X_train, lambda_val = 1, k = 128, learning_rate=1):\n",
    "    X = (torch.FloatTensor(X_train)\n",
    "    D_weights = Variable(torch.FloatTensor(X_train.shape[1], k).normal_(),requires_grad=True)\n",
    "    R_train = Variable(torch.FloatTensor(k, X_train.shape[0]).normal_(),requires_grad=True)\n",
    "#     minimization_term = torch.norm(X - torch.transpose(torch.mm(D_weights, R_weights)),2)\n",
    "#     regularization_term = lambda_val*(torch.nonzero(R_weights.data).size(0))\n",
    "\n",
    "    # Normal MSE loss for autoencoder:\n",
    "#     loss = minimization_term + regularization_term\n",
    "    D_iter = iter(D_weights)\n",
    "    R_iter = iter(R_train)\n",
    "    optimizer = optim.SGD(D_iter, lr= 0.01)\n",
    "    optimizer_alpha = optim.SGD(R_iter, lr = 0.01)    \n",
    "    num_epochs = 100\n",
    "\n",
    "    errors = []\n",
    "    for i in range(num_epochs):\n",
    "        minimization_term = torch.norm(X - torch.transpose(torch.mm(D_weights, R_train),0,1),2)\n",
    "        regularization_term = lambda_val*(torch.nonzero(R_train.data).size(0))\n",
    "        loss = minimization_term+regularization_term\n",
    "        loss /= X_train.shape[0]\n",
    "        # ===================backward====================\n",
    "        optimizer_alpha.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        optimizer_alpha.step()\n",
    "        print(\"Training loss (MSE) : %.4f\" % (loss))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(1 + np.arange(num_epochs), errors, label='Training loss')\n",
    "    plt.title('Training loss v/s Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('dict_training.png')\n",
    "\n",
    "    return Dw, R_train.T\n",
    "\n",
    "\n",
    "\n",
    "X_train,Y_train,X_test, Y_test = Train_data_t, Train_labels_t, Test_data, Test_labels\n",
    "\n",
    "\n",
    "\n",
    "# def find_reprs(X_train, D_train, lambda_val = 1, k=128, learning_rate=1):\n",
    "#     X = tf.placeholder(\"float\", X_train.shape)\n",
    "\n",
    "#     D = tf.placeholder(\"float\", D_train.shape)\n",
    "#     R = tf.placeholder(\"float\", (k, X_train.shape[0]))\n",
    "    \n",
    "#     R_weights = tf.Variable(tf.random_normal([k, X_train.shape[0]]))\n",
    "    \n",
    "#     minimization_term = tf.norm(X - tf.transpose(tf.matmul(D, R_weights)), ord='fro', axis=(0,1))\n",
    "#     regularization_term = lambda_val * tf.cast(tf.count_nonzero(R_weights), tf.float32)\n",
    "\n",
    "#     # Normal MSE loss for autoencoder:\n",
    "#     loss = minimization_term + regularization_term\n",
    "#     loss /= X_train.shape[0]\n",
    "#     optimizer = tf.train.AdadeltaOptimizer(learning_rate)\n",
    "    \n",
    "#     R_new = optimizer.minimize(loss, var_list=[R_weights])\n",
    "    \n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     num_epochs = 50\n",
    "\n",
    "#     # Train model\n",
    "#     R_train = None\n",
    "#     for i in range(num_epochs):\n",
    "\n",
    "#         # Update R\n",
    "#         _, l, R_train = sess.run([R_new, loss, R_weights],feed_dict={X: X_train, D: D_train})\n",
    "#         print(\"Representation finding loss (MSE) : %.4f\" % (l))\n",
    "\n",
    "#     return R_train.T\n",
    "\n",
    "D, features_train = dictionary_learning(X_train)\n",
    "# features_test = find_reprs(test_flat_X, D, 0.01, 100, 100)\n",
    "#features_test = np.linalg.pinv(test_flat_X, D.T)\n",
    "\n",
    "\n",
    "\n",
    "def eucledian_predict(X_tr, Y_tr, X_te, Y_te):\n",
    "    correct = 0\n",
    "    for i, test in enumerate(X_te):\n",
    "        distances = []\n",
    "        for point in X_tr:\n",
    "            distances.append(np.linalg.norm(test - point))\n",
    "        label = Y_tr[np.argmin(distances)]\n",
    "        if np.argmax(label) == np.argmax(Y_te[i]):\n",
    "            correct += 1\n",
    "        accuracy  = correct / (1.0 * Y_te.shape[0])\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# print(\"Dictionary-learning features based L2 accuracy:\",eucledian_prediction(features_train, Y_train, features_test, Y_test))\n",
    "\n",
    "# if not os.path.exists(\"atoms\"):\n",
    "#         os.makedirs(\"atoms\")\n",
    "\n",
    "# for i, atom in enumerate(D.T):\n",
    "#         vis_atom = (atom.reshape((96, 96, 3)) * 255).astype('uint8')\n",
    "#         plt.clf()\n",
    "#         plt.imshow(vis_atom)\n",
    "#         plt.savefig(\"atoms/\" + str(i+1) + \"atom.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
