{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "path = \"../AML_Assignment2/cifar/\"\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extractImagesAndLabels(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dicte = pickle.load(f,encoding='bytes')\n",
    "    images = dicte[b'data']\n",
    "    Matrix=[]\n",
    "    image_mean = np.mean(images)\n",
    "    for i in images:\n",
    "        ingle_img_reshaped = np.reshape(i,(3, 32,32))\n",
    "        ingle_img_reshaped = ingle_img_reshaped - image_mean\n",
    "        ingle_img_reshaped = ingle_img_reshaped/128\n",
    "#         ingle_img_reshaped = np.transpose(ingle_img_reshaped, (1,2,0))\n",
    "        #x=np.dot(ingle_img_reshaped[...,:3], [0.299, 0.587, 0.114])\n",
    "#         x= ingle_img_reshaped.flatten()\n",
    "        Matrix.append(ingle_img_reshaped)\n",
    "    #images = np.transpose(images, (1,2,0))\n",
    "   \n",
    "    Matrix = np.array(Matrix)\n",
    "    labels = dicte[b'labels']\n",
    "    labels = np.array(labels)\n",
    "    #print labels.shape\n",
    "    return Matrix, labels\n",
    " \n",
    "#     labels = dict['labels']\n",
    "\n",
    "def extractCategories(path, file):\n",
    "    f = open(path+file, 'rb')\n",
    "    dict = pickle.load(f,encoding='bytes')\n",
    "    return dict[b'label_names']\n",
    "\n",
    "def saveCifarImage(array, path, file):\n",
    "    # array is 3x32x32. cv2 needs 32x32x3\n",
    "    array = array.asnumpy().transpose(1,2,0)\n",
    "    # array is RGB. cv2 needs BGR\n",
    "    array = cv2.cvtColor(array, cv2.COLOR_RGB2BGR)\n",
    "    # save to PNG file\n",
    "    return cv2.imwrite(path+file+\".png\", array)\n",
    "\n",
    "\n",
    "Train_data, Train_labels = extractImagesAndLabels(path, \"data_batch_1\")\n",
    "Train_data_2, Train_labels_2 = extractImagesAndLabels(path,\"data_batch_2\")\n",
    "Train_data_3, Train_labels_3 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_3, Train_labels_3 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_4, Train_labels_4 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_5, Train_labels_5 = extractImagesAndLabels(path, \"data_batch_3\")\n",
    "Train_data_t = np.concatenate((Train_data, Train_data_2,Train_data_3,Train_data_4,Train_data_5), axis=0)\n",
    "Train_labels_t = np.concatenate((Train_labels,Train_labels_2,Train_labels_3,Train_labels_4,Train_labels_5), axis=0)\n",
    "print (Train_data_t.shape)\n",
    "Test_data, Test_labels = extractImagesAndLabels(path, \"test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0] # number of rows\n",
    "        fan_in = size[1] # number of columns\n",
    "        variance = np.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)\n",
    "        \n",
    "# def grad_storer(m):\n",
    "#     if isinstance(m, nn.Conv2d):\n",
    "#         gradient = m.\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),\n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "#         torch.nn.init.xavier_uniform(self.layer1.weight)\n",
    "        self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "    \n",
    "        self.fc1 = nn.Linear(800, 400)\n",
    "        self.pre = nn.PReLU()\n",
    "        self.fc2 = nn.Linear(400, num_classes)\n",
    "        self.pre2 = nn.PReLU()\n",
    "        self.soft = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "#         print(type(out))\n",
    "#         print(g)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.pre(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.pre2(out)\n",
    "        out = self.soft(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet2(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),            \n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "#         torch.nn.init.xavier_uniform(self.layer1.weight)\n",
    "        self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=1))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                       nn.Conv2d(32,64,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU()\n",
    "                    )\n",
    "        self.layer4 = nn.Sequential(\n",
    "                       nn.Conv2d(64,64,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU())\n",
    "        self.fc1 = nn.Linear(2304, 500)\n",
    "        self.pre = nn.PReLU()\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "        self.pre2 = nn.PReLU()\n",
    "        self.soft = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = out.view(out\n",
    "#         out = out.reshape()\n",
    "#         print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "#         print(out.size())\n",
    "        out = self.pre(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.pre2(out)\n",
    "#         print(out.size())\n",
    "        out = self.soft(out)\n",
    "#         print(out.size())\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet3(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),            \n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "#         torch.nn.init.xavier_uniform(self.layer1.weight)\n",
    "        self.layer2 = nn.Sequential(\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=0),\n",
    "                    nn.PReLU(),\n",
    "                    nn.MaxPool2d(kernel_size=3, stride=1))\n",
    "        self.layer3 = nn.Sequential(\n",
    "                       nn.Conv2d(32,64,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU()\n",
    "                    )\n",
    "        self.layer4 = nn.Sequential(\n",
    "                       nn.Conv2d(64,64,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "                       nn.Conv2d(64,128,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "                       nn.Conv2d(128,128,kernel_size=3, stride=1, padding=0),\n",
    "                        nn.PReLU())\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.pre = nn.PReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.pre2 = nn.PReLU()\n",
    "        self.soft = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "#         out = out.view(out\n",
    "#         out = out.reshape()\n",
    "#         print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "#         print(out.size())\n",
    "        out = self.pre(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.pre2(out)\n",
    "#         print(out.size())\n",
    "        out = self.soft(out)\n",
    "#         print(out.size())\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria  = nn.CrossEntropyLoss()\n",
    "def train(model, device, train_loader, optimizer,epoch, grad_container):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data,target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criteria(output, target)\n",
    "        loss.backward()\n",
    "        grad_of_param = {}\n",
    "        for name, parameter in model.named_parameters():\n",
    "#             grad_of_param[name] = parameter.grad\n",
    "            gradient_layer1_filter1_channel1 = parameter.grad[0][0][0][2]\n",
    "            grad_container.append(gradient_layer1_filter1_channel1)\n",
    "            break\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "def test(model, device, test_loader, set_name, contain,acc):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data,target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += criteria(output, target).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    contain.append(test_loss)\n",
    "    acc.append(correct/len(test_loader.dataset))\n",
    "    print(\"Accuracy......\")\n",
    "    print('\\n'+set_name+': Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "\n",
    "Train_data_t = torch.from_numpy(Train_data_t)\n",
    "Train_labels_t = torch.from_numpy(Train_labels_t)\n",
    "train_data = data_utils.TensorDataset(Train_data_t, Train_labels_t)\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "Test_data =torch.from_numpy(Test_data)\n",
    "Test_labels= torch.from_numpy(Test_labels)\n",
    "test_data = data_utils.TensorDataset(Test_data, Test_labels)\n",
    "test_loader = data_utils.DataLoader(test_data, batch_size=50, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet3(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (pre): PReLU(num_parameters=1)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (pre2): PReLU(num_parameters=1)\n",
      "  (soft): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "model = ConvNet3(num_classes).cuda()\n",
    "# model.apply(weight_init)\n",
    "print(model)\n",
    "# exam = torch.FloatTensor(Train_data_t[0,:,:,:])\n",
    "# exam = exam.unsqueeze(0)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# learning_rate = 0.1\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# num_epochs=100\n",
    "# from torch.autograd import Variable\n",
    "# total_step =len(Train_data_t)\n",
    "# exam = exam.to(device)\n",
    "# exam = torch.transpose(exam,2,0,1)\n",
    "# outputs = model(exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_epochs=100\n",
    "from torch.autograd import Variable\n",
    "total_step =len(Train_data_t)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit1_aml/anaconda3/envs/mohitpy36/lib/python3.6/site-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.302207\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.303125\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302689\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302729\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302831\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302486\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302300\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302839\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302445\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302625\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0461, Accuracy: 4979/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0461, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301949\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302661\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302513\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302294\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302465\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302314\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302649\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301792\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.303074\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302112\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0461, Accuracy: 4979/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0461, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.302096\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302567\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302506\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302783\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302685\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.303053\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302158\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302882\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302721\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302621\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0461, Accuracy: 4979/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0461, Accuracy: 1000/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301988\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302557\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.301982\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302383\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302621\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302825\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.301956\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302792\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302230\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302834\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0461, Accuracy: 5008/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0461, Accuracy: 1013/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301878\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302699\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302922\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302146\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302893\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302348\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302809\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302283\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302529\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302926\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0461, Accuracy: 5490/50000 (11%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0461, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.302751\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302643\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302897\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302505\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302241\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302794\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302311\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302563\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302891\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302063\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0460, Accuracy: 5833/50000 (12%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0460, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.302402\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302445\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302586\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302682\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302901\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302851\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302469\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302717\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302660\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.302500\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0460, Accuracy: 5886/50000 (12%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0460, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.302391\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302366\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302066\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.302133\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302361\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302555\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.302253\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.302169\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302627\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.301965\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0460, Accuracy: 7652/50000 (15%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0460, Accuracy: 1566/10000 (16%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301957\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302136\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.301883\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.301321\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.302262\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.302005\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.301039\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301125\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.302140\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.300493\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0460, Accuracy: 8920/50000 (18%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0460, Accuracy: 1816/10000 (18%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.300519\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.302078\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.302563\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.299499\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.300838\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.300346\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.298988\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.279979\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.294167\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.257715\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0453, Accuracy: 8746/50000 (17%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0452, Accuracy: 1787/10000 (18%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.246308\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.286338\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.226037\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.226482\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.244203\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.232663\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.271627\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.212502\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.182044\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.189736\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0442, Accuracy: 11596/50000 (23%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0441, Accuracy: 2303/10000 (23%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.174892\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.196303\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.288504\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.175979\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.239361\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.142456\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.226352\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.266599\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.118684\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.277844\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0440, Accuracy: 12052/50000 (24%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0440, Accuracy: 2427/10000 (24%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.087537\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.184127\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.220866\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.175979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.107005\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.128739\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.213462\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.209953\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.112003\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.113550\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0430, Accuracy: 15077/50000 (30%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0431, Accuracy: 2914/10000 (29%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.120081\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.161078\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.147513\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.133208\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.123863\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.156276\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.148696\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.128839\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.142096\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.191419\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0421, Accuracy: 17477/50000 (35%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0422, Accuracy: 3410/10000 (34%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.135335\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.102390\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.081620\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.121374\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.070687\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.119320\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.067574\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.071742\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.052541\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.104234\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0419, Accuracy: 17693/50000 (35%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0422, Accuracy: 3387/10000 (34%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.100391\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.046237\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.067011\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.162652\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.047617\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.018892\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.029130\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.957387\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.105396\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.995171\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0410, Accuracy: 20415/50000 (41%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0413, Accuracy: 3927/10000 (39%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.111311\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.020443\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.048285\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.079708\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.009514\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.033474\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.982943\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.170542\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.051588\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.031987\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0404, Accuracy: 21781/50000 (44%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0406, Accuracy: 4279/10000 (43%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.929977\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.955290\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.141212\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.057961\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.034872\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.072726\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.026461\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.153299\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.069212\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.936237\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0400, Accuracy: 22850/50000 (46%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0403, Accuracy: 4434/10000 (44%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.938286\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.906812\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.997793\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.004613\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.969702\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.934064\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.021595\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.032313\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.974360\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.849407\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0395, Accuracy: 24087/50000 (48%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0398, Accuracy: 4619/10000 (46%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.005381\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.949463\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.949930\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.944782\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.007582\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.932557\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.894759\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.927235\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.128236\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.997003\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0393, Accuracy: 24533/50000 (49%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0396, Accuracy: 4752/10000 (48%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.065731\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.942289\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.926352\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.913612\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.916480\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.033191\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.040907\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.982814\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.904894\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.979777\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0388, Accuracy: 25990/50000 (52%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0392, Accuracy: 4958/10000 (50%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.964430\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.028456\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.019714\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.917329\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.909247\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.051438\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.025429\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.826448\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.936839\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.946391\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0388, Accuracy: 25848/50000 (52%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0393, Accuracy: 4920/10000 (49%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.057912\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.952717\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.879010\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.773117\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.041444\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.911624\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.930089\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.007809\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.891317\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.990205\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0381, Accuracy: 27554/50000 (55%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0387, Accuracy: 5242/10000 (52%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.943610\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.914086\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.838441\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.832096\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.917518\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.030108\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.958018\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.956468\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.915870\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.083066\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0385, Accuracy: 26807/50000 (54%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0389, Accuracy: 5087/10000 (51%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.789529\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.952113\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.911107\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.974157\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.983095\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.956627\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.884326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.943882\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.790714\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.916059\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0379, Accuracy: 28044/50000 (56%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0385, Accuracy: 5329/10000 (53%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.854036\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.932893\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.879400\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.923613\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.873807\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.859754\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.022154\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.814656\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.957877\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.836285\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0378, Accuracy: 28635/50000 (57%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0383, Accuracy: 5418/10000 (54%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.920631\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.941410\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.013343\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.838929\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.786319\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.859462\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.775780\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.865898\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.047490\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.980151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0376, Accuracy: 28881/50000 (58%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0384, Accuracy: 5380/10000 (54%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.918794\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.945535\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.949487\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.806053\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.886732\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.815894\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.896953\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.800704\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.843799\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.773570\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0373, Accuracy: 29770/50000 (60%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0380, Accuracy: 5565/10000 (56%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.870579\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.749146\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.812337\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.800103\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.841419\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.741511\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.901679\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.765980\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.897114\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.969438\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0376, Accuracy: 29038/50000 (58%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0382, Accuracy: 5470/10000 (55%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.029575\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.820990\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.916837\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.832902\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.820060\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.910153\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.831140\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.874716\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.854353\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.824807\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0370, Accuracy: 30376/50000 (61%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0379, Accuracy: 5655/10000 (57%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.784102\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.847363\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.786214\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.959399\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.964617\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.909883\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.801453\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.881107\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.800536\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.968385\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0371, Accuracy: 30168/50000 (60%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0379, Accuracy: 5628/10000 (56%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.744241\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.879946\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.809569\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.961155\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.978381\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.757875\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.966033\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.833212\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.832640\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.912672\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0367, Accuracy: 31335/50000 (63%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0376, Accuracy: 5789/10000 (58%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.748326\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.758697\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.772805\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.846645\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.938329\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.788395\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.844968\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.911728\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.885135\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.874645\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0372, Accuracy: 29855/50000 (60%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0380, Accuracy: 5568/10000 (56%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.809512\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.846228\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.771423\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.838350\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.955017\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.805442\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.800699\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.850448\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.770304\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.983679\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0365, Accuracy: 31675/50000 (63%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0375, Accuracy: 5833/10000 (58%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.969681\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.783181\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.729525\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.735251\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.872862\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.899018\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.884747\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.848747\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.904342\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.842138\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0361, Accuracy: 32826/50000 (66%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0372, Accuracy: 5974/10000 (60%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.724856\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.796591\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.876537\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.766322\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.812105\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.789087\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.670996\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.882406\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.863277\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.967453\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0372, Accuracy: 29969/50000 (60%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0380, Accuracy: 5591/10000 (56%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.796987\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.707304\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.750484\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.797711\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.756032\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.868525\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.770086\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.847066\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.770915\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.855127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0363, Accuracy: 32157/50000 (64%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0374, Accuracy: 5879/10000 (59%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.776533\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.784449\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.895984\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.862846\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.909371\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.801766\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.818745\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.867012\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.799742\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.832043\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0369, Accuracy: 30645/50000 (61%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0378, Accuracy: 5708/10000 (57%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.834594\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.798866\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.760072\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.810030\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.865457\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.817049\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.885262\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.843355\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.841611\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.880586\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0364, Accuracy: 32029/50000 (64%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0375, Accuracy: 5809/10000 (58%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.889669\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.792822\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.735473\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.846932\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.898805\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.874659\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.821744\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.862178\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.762685\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.892470\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0358, Accuracy: 33439/50000 (67%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0371, Accuracy: 6069/10000 (61%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.838452\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.938559\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.840340\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.769560\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.920701\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.849635\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.860605\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.698179\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.858580\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.754527\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0359, Accuracy: 33219/50000 (66%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0371, Accuracy: 6017/10000 (60%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.819709\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.747988\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.749425\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.760708\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.752710\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.891753\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.902558\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.805353\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.831650\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.708769\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0363, Accuracy: 32260/50000 (65%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0376, Accuracy: 5789/10000 (58%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.828078\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.785375\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.759587\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.789443\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.828061\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.847261\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.813795\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.788966\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.916775\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.741569\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0361, Accuracy: 32758/50000 (66%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0373, Accuracy: 5964/10000 (60%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.751805\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.889658\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.859047\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.752673\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.922694\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.773000\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.851055\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.812738\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.835014\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.904120\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0360, Accuracy: 32888/50000 (66%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0373, Accuracy: 5969/10000 (60%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.847494\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.802591\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.839885\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.952599\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.825384\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.821161\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.809761\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.854796\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.835712\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.837236\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0360, Accuracy: 33056/50000 (66%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0372, Accuracy: 5977/10000 (60%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.715056\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.774655\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.862161\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.752183\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.793236\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.892677\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.795549\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.957767\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.892752\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.840613\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0366, Accuracy: 31536/50000 (63%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0377, Accuracy: 5759/10000 (58%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.799015\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.747503\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.724143\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.808237\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.708914\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.812453\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.708128\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.702552\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.774839\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.780244\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0369, Accuracy: 30831/50000 (62%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0378, Accuracy: 5680/10000 (57%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.865829\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.789680\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.910731\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.004391\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.738427\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.899970\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.922226\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.920628\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.705910\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.968199\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0372, Accuracy: 30000/50000 (60%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0380, Accuracy: 5604/10000 (56%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.837841\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.914199\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.941439\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.968759\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.709109\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.910849\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.820176\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.939925\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.846709\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 1.918477\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0377, Accuracy: 28858/50000 (58%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0384, Accuracy: 5423/10000 (54%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.850109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.874858\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 1.896440\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 1.868475\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.040565\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 1.940091\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.037739\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 1.892488\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 1.968534\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.080357\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0393, Accuracy: 24734/50000 (49%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0399, Accuracy: 4656/10000 (47%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 1.893137\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.939702\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.140301\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.053228\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.010286\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.021138\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 1.960441\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.021282\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.061605\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.200832\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0398, Accuracy: 23609/50000 (47%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0402, Accuracy: 4499/10000 (45%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.021132\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 1.779938\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.020005\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.181607\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 1.961150\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.100716\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.081200\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.181151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.061062\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.181099\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0459, Accuracy: 8383/50000 (17%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0460, Accuracy: 1625/10000 (16%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321123\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.241151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.259806\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.185096\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.221151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0447, Accuracy: 11302/50000 (23%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0448, Accuracy: 2204/10000 (22%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.221151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0451, Accuracy: 10394/50000 (21%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0452, Accuracy: 2032/10000 (20%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.161151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.281151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.461151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0473, Accuracy: 986/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 4977/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 987/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5043/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 999/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.461151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.221151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.441151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.401151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.221151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.421151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.261151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.401151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.461151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.421151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.361151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.421151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.461151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.221151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.461151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.401151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.401151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.321151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.261151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.421151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.421151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.441151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.281151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.401151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.421151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.381151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 2.281151\n",
      "Train Epoch: 100 [5000/50000 (10%)]\tLoss: 2.341151\n",
      "Train Epoch: 100 [10000/50000 (20%)]\tLoss: 2.301151\n",
      "Train Epoch: 100 [15000/50000 (30%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [20000/50000 (40%)]\tLoss: 2.381151\n",
      "Train Epoch: 100 [25000/50000 (50%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [30000/50000 (60%)]\tLoss: 2.401151\n",
      "Train Epoch: 100 [35000/50000 (70%)]\tLoss: 2.321151\n",
      "Train Epoch: 100 [40000/50000 (80%)]\tLoss: 2.361151\n",
      "Train Epoch: 100 [45000/50000 (90%)]\tLoss: 2.341151\n",
      "Accuracy......\n",
      "\n",
      "Training_set: Average loss: 0.0472, Accuracy: 5166/50000 (10%)\n",
      "\n",
      "Accuracy......\n",
      "\n",
      "Test_Set: Average loss: 0.0472, Accuracy: 1014/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_train=[]\n",
    "acc_train=[]\n",
    "loss_test=[]\n",
    "acc_test=[]\n",
    "ep=[]\n",
    "gradient=[]\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    ep.append(epoch)\n",
    "    train(model, device, train_loader, optimizer, num_epochs,gradient)\n",
    "    test(model, device, train_loader, \"Training_set\",loss_train, acc_train)\n",
    "    test(model, device, test_loader, \"Test_Set\",loss_test,acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def loss_plot(ep, loss_train, loss_test, subject):\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(subject)\n",
    "    plt.plot(ep,loss_train)\n",
    "    plt.plot(ep,loss_test)\n",
    "    plt.legend([\"Loss-Train\", \"Loss-Test\"], loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "loss_plot(ep,loss_train,loss_test, \"With 3 Blocks of Convolution\")\n",
    "def acc_plot(ep, acc_test,acc_train,subject):\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(subject)\n",
    "    plt.plot(ep,acc_train)\n",
    "    plt.plot(ep,acc_test)\n",
    "    plt.legend([\"Acuracy-Train\", \"Accuracy-Test\"], loc='lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_plot(ep,acc_train,acc_test, \"With 3 Blocks of Convolution\")\n",
    "interpolate_grad =[gradient[i] for i in range(100000) if i%1000==0]\n",
    "es = [i for i in range(100000)]\n",
    "print(len(interpolate_grad))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient\")\n",
    "plt.title(\"With Single Conv Block CNN\")\n",
    "plt.plot(es,gradient)\n",
    "# plt.plot(ep,acc_test)\n",
    "plt.legend([\"Gradient\"], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7f603d9588>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpolate_grad =[gradient[i] for i in range(100000) if i%1000==0]\n",
    "es = [i for i in range(100000)]\n",
    "print(len(interpolate_grad))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Gradient\")\n",
    "plt.title(\"With Single Conv Block CNN\")\n",
    "plt.plot(es,gradient)\n",
    "# plt.plot(ep,acc_test)\n",
    "plt.legend([\"Gradient\"], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "), Sequential(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): PReLU(num_parameters=1)\n",
      "), Linear(in_features=512, out_features=256, bias=True), PReLU(num_parameters=1), Linear(in_features=256, out_features=10, bias=True), PReLU(num_parameters=1), Softmax()]\n",
      "(32, 32, 3, 3)\n",
      "6 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_kernels(tensor, num_cols=6):\n",
    "    print (tensor.shape)\n",
    "    if not tensor.ndim==4:\n",
    "        raise Exception(\"assumes a 4D tensor\")\n",
    "    if not tensor.shape[-1]==3:\n",
    "        raise Exception(\"last dim needs to be 3 to plot\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    print(num_cols,num_rows)\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i][1])\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "\n",
    "filters = model.modules\n",
    "body_model = [i for i in model.children()]\n",
    "print(body_model)\n",
    "layer1 = body_model[1][0]\n",
    "tensor = layer1.weight.data.cpu().numpy()\n",
    "# print(type(tensor))\n",
    "plot_kernels(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAXOUT ACTIVATION ON ALL 3  TYPES OF CNN:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "class Maxout(Function):\n",
    "\n",
    "    # Note that both forward and backward are @staticmethods\n",
    "    @staticmethod\n",
    "    # bias is an optional argument\n",
    "    def forward(ctx, input):\n",
    "        x = input\n",
    "        max_out=4    #Maxout Parameter\n",
    "        kernels = x.shape[1]  # to get how many kernels/output\n",
    "        feature_maps = int(kernels / max_out)\n",
    "        out_shape = (x.shape[0], feature_maps, max_out, x.shape[2], x.shape[3])\n",
    "        x= x.view(out_shape)\n",
    "        y, indices = torch.max(x[:, :, :], 2)\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.indices=indices\n",
    "        ctx.max_out=max_out\n",
    "        return y\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input1,indices,max_out= ctx.saved_variables[0],Variable(ctx.indices),ctx.max_out\n",
    "        input=input1.clone()\n",
    "        for i in range(max_out):\n",
    "            a0=indices==i\n",
    "            input[:,i:input.data.shape[1]:max_out]=a0.float()*grad_output\n",
    "      \n",
    "\n",
    "        return input\n",
    "    \n",
    "# code reffered from https://github.com/Usama113/Maxout-PyTorch/blob/master/Maxout.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-121-10f70a1c584c>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-121-10f70a1c584c>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    nn.MaxPool2d(kernel_size=3, stride=1))\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ConvNet3(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0),            \n",
    "        self.mx1 = Maxout.apply,\n",
    "         self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2))\n",
    "#         torch.nn.init.xavier_uniform(self.layer1.weight)\n",
    "        self.layer2 = nn.Conv2d(8, 32, kernel_size=3, stride=1, padding=0),\n",
    "        self.mx2 = Maxout.apply\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=1))\n",
    "        self.layer3 = nn.Conv2d(8,64,kernel_size=3, stride=1, padding=0),\n",
    "         self.mx3 = Maxout.apply\n",
    "        self.layer4 = nn.Conv2d(8,64,kernel_size=3, stride=1, padding=0),\n",
    "        self.mx4 = Maxout.apply\n",
    "        self.layer5 = nn.Conv2d(16,128,kernel_size=3, stride=1, padding=0),\n",
    "        self.mx5= Maxout.apply\n",
    "        self.layer6 = nn.Conv2d(16,128,kernel_size=3, stride=1, padding=0),\n",
    "        self.mx6=Maxout.apply\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.pre = nn.PReLU()\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.pre2 = nn.PReLU()\n",
    "        self.soft = nn.Softmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "#         out = out.view(out\n",
    "#         out = out.reshape()\n",
    "#         print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "#         print(out.size())\n",
    "        out = self.pre(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.pre2(out)\n",
    "#         print(out.size())\n",
    "        out = self.soft(out)\n",
    "#         print(out.size())\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = Variable(torch.cuda.FloatTensor([0]))\n",
    "# los =[]\n",
    "# epoch=[]\n",
    "# for epoch in range(num_epochs):\n",
    "    \n",
    "#     for i, (images,labels) in enumerate(train_loader):\n",
    "#         images = images.type(torch.FloatTensor)\n",
    "        \n",
    "# #             images = torch.FloatTensor(images)\n",
    "#         images = images.to(device)\n",
    "#         labels = labels.to(device)\n",
    "# #             print(Train_labels_t[i])\n",
    "# #             labels = Variable(torch.LongTensor([Train_labels_t[i]])).to(device)\n",
    "#         # Forward pass\n",
    "# #             print(images.size())\n",
    "# #             images = images.unsqueeze(0)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "# #             print(outputs,\"        \",labels)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward and optimize\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         los.append(loss.data[0])\n",
    "            \n",
    "# #             print (loss.data[0])\n",
    "# #             lo.append(loss_contrastive.data[0])\n",
    "            \n",
    "# #             loss_contrastive += Variable(torch.FloatTensor([0]))\n",
    "# #             loss_contrastive.backward(retain_graph=True)\n",
    "            \n",
    "# #         optimizer.step()\n",
    "# #         loss = Variable(torch.cuda.FloatTensor([0]))\n",
    "# #         else:\n",
    "# #             images = torch.FloatTensor(images)\n",
    "# #             images = images.to(device)\n",
    "# # #             print(Train_labels_t[i])\n",
    "# #             labels = Variable(torch.LongTensor([Train_labels_t[i]])).to(device)\n",
    "# #             # Forward pass\n",
    "# # #             print(images.size())\n",
    "# #             images = images.unsqueeze(0)\n",
    "# #             outputs = model(images)\n",
    "# # #             print(outputs,\"        \",labels)\n",
    "# #             loss += criterion(outputs, labels)\n",
    "            \n",
    "#         if (i+1) % 100 == 0:\n",
    "#             print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "#                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(los, open(\"los_1.pkl\",\"wb\"))\n",
    "# torch.save(model, \"model_1.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load(\"model_1.pth\")\n",
    "# print(len(los))\n",
    "# new_l=[]\n",
    "# for i,l in enumerate(los):\n",
    "#     if i%1000==0:\n",
    "#         new_l.append(l)\n",
    "\n",
    "# epoch = [i for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.xlabel(\"Iteration\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.plot(epoch,new_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
